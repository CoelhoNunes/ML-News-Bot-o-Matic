[
  {
    "timestamp": "2025-09-14_02-00",
    "source": "mindmatters.ai",
    "title": "And Sci Fi Thought AI Was Going To… Take Over?",
    "url": "https://mindmatters.ai/2025/09/and-sci-fi-thought-ai-was-going-to-take-over/",
    "summary": "Sci Fi Thought AI AI was going to… Take Over",
    "tags": [
      "other"
    ]
  },
  {
    "timestamp": "2025-09-14_02-00",
    "source": "MarkTechPost",
    "title": "Google AI Releases VaultGemma: The Largest and Most Capable Open Model (1B-parameters) Trained from Scratch with Differential Privacy",
    "url": "https://www.marktechpost.com/2025/09/13/google-ai-releases-vaultgemma-the-largest-and-most-capable-open-model-1b-parameters-trained-from-scratch-with-differential-privacy/",
    "summary": "Google AI releases VaultGemma: The Largest and Most Capable Open Model (1B-parameters) Trained from Scratch with Differential",
    "tags": [
      "news"
    ]
  },
  {
    "timestamp": "2025-09-14_02-00",
    "source": "StartupHub.ai",
    "title": "Google Meet AI Translation: Breaking Language Barriers",
    "url": "https://www.startuphub.ai/ai-news/ai-research/2025/google-meet-ai-translation-breaking-language-barriers/",
    "summary": "Google Meet AI Translation: Breaking Language Bar",
    "tags": [
      "news"
    ]
  },
  {
    "timestamp": "2025-09-14_02-00",
    "source": "MarkTechPost",
    "title": "BentoML Released llm-optimizer: An Open-Source AI Tool for Benchmarking and Optimizing LLM Inference",
    "url": "https://www.marktechpost.com/2025/09/12/bentoml-released-llm-optimizer-an-open-source-ai-tool-for-benchmarking-and-optimizing-llm-inference/",
    "summary": "BentoML released llm-optimizer: An Open-Source AI Tool for Benchmarking and Optimizing LLM In",
    "tags": [
      "news"
    ]
  },
  {
    "timestamp": "2025-09-14_02-00",
    "source": "MarkTechPost",
    "title": "Meet mmBERT: An Encoder-only Language Model Pretrained on 3T Tokens of Multilingual Text in over 1800 Languages and 2–4× Faster than Previous Models",
    "url": "https://www.marktechpost.com/2025/09/10/meet-mmbert-an-encoder-only-language-model-pretrained-on-3t-tokens-of-multilingual-text-in-over-1800-languages-and-2-4x-faster-than-previous-models/",
    "summary": "mmBERT: An Encoder-only Language Model Pretrained on 3T Tokens of Multilingual Text in over 1800 Languages and 2–4× Faster than Previous Models",
    "tags": [
      "other"
    ]
  }
]